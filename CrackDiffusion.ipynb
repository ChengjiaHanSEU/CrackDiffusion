{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow.keras.layers as nn\n",
    "\n",
    "from tensorflow import einsum\n",
    "from einops import rearrange\n",
    "from einops.layers.tensorflow import Rearrange\n",
    "\n",
    "import math\n",
    "from inspect import isfunction\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import time\n",
    "from tensorflow.python.data.experimental import AUTOTUNE\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import imutils\n",
    "import skimage\n",
    "from skimage.metrics import structural_similarity\n",
    "import time\n",
    "from skimage import filters, img_as_ubyte,morphology,measure\n",
    "from scipy.ndimage import label\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################ops#########################\n",
    "# helpers functions\n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "def cycle(dl):\n",
    "    while True:\n",
    "        for data in dl:\n",
    "            yield data\n",
    "\n",
    "def num_to_groups(num, divisor):\n",
    "    groups = num // divisor\n",
    "    remainder = num % divisor\n",
    "    arr = [divisor] * groups\n",
    "    if remainder > 0:\n",
    "        arr.append(remainder)\n",
    "    return arr\n",
    "\n",
    "def normalize_to_neg_one_to_one(img):\n",
    "    return img * 2 - 1\n",
    "\n",
    "def unnormalize_to_zero_to_one(t):\n",
    "    return (t + 1) * 0.5\n",
    "\n",
    "# small helper modules\n",
    "class Identity(Layer):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        return tf.identity(x)\n",
    "\n",
    "class EMA(Layer):\n",
    "    def __init__(self, beta=0.995):\n",
    "        super(EMA, self).__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    @tf.function\n",
    "    def update_model_average(self, old_model, new_model):\n",
    "        for old_weight, new_weight in zip(old_model.weights, new_model.weights):\n",
    "            assert old_weight.shape == new_weight.shape\n",
    "\n",
    "            old_weight.assign(self.update_average(old_weight, new_weight))\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new\n",
    "\n",
    "class Residual(Layer):\n",
    "    def __init__(self, fn):\n",
    "        super(Residual, self).__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        return self.fn(x, training=training) + x\n",
    "\n",
    "class SinusoidalPosEmb(Layer):\n",
    "    def __init__(self, dim, max_positions=10000):\n",
    "        super(SinusoidalPosEmb, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.max_positions = max_positions\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(self.max_positions) / (half_dim - 1)\n",
    "        emb = tf.exp(tf.range(half_dim, dtype=tf.float32) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "\n",
    "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=-1)\n",
    "\n",
    "        return emb\n",
    "\n",
    "def Upsample(dim):\n",
    "    return nn.Conv2DTranspose(filters=dim, kernel_size=4, strides=2, padding='SAME')\n",
    "\n",
    "def Downsample(dim):\n",
    "    return nn.Conv2D(filters=dim, kernel_size=4, strides=2, padding='SAME')\n",
    "\n",
    "class LayerNorm(Layer):\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "        self.g = tf.Variable(tf.ones([1, 1, 1, dim]))\n",
    "        self.b = tf.Variable(tf.zeros([1, 1, 1, dim]))\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        var = tf.math.reduce_variance(x, axis=-1, keepdims=True)\n",
    "        mean = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "\n",
    "        x = (x - mean) / tf.sqrt((var + self.eps)) * self.g + self.b\n",
    "        return x\n",
    "\n",
    "class PreNorm(Layer):\n",
    "    def __init__(self, dim, fn):\n",
    "        super(PreNorm, self).__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = LayerNorm(dim)\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)\n",
    "\n",
    "class SiLU(Layer):\n",
    "    def __init__(self):\n",
    "        super(SiLU, self).__init__()\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        return x * tf.nn.sigmoid(x)\n",
    "\n",
    "def gelu(x, approximate=False):\n",
    "    if approximate:\n",
    "        coeff = tf.cast(0.044715, x.dtype)\n",
    "        return 0.5 * x * (1.0 + tf.tanh(0.7978845608028654 * (x + coeff * tf.pow(x, 3))))\n",
    "    else:\n",
    "        return 0.5 * x * (1.0 + tf.math.erf(x / tf.cast(1.4142135623730951, x.dtype)))\n",
    "\n",
    "class GELU(Layer):\n",
    "    def __init__(self, approximate=False):\n",
    "        super(GELU, self).__init__()\n",
    "        self.approximate = approximate\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        return gelu(x, self.approximate)\n",
    "\n",
    "def linear_beta_schedule(timesteps):\n",
    "    scale = 1000 / timesteps\n",
    "    beta_start = scale * 0.0001\n",
    "    beta_end = scale * 0.02\n",
    "\n",
    "    return tf.cast(tf.linspace(beta_start, beta_end, timesteps), tf.float32)\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s = 0.008):\n",
    "    \"\"\"\n",
    "    cosine schedule\n",
    "    as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = tf.cast(tf.linspace(0, timesteps, steps), tf.float32)\n",
    "\n",
    "    alphas_cumprod = tf.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "\n",
    "    return tf.clip_by_value(betas, 0, 0.999)\n",
    "\n",
    "def extract(x, t):\n",
    "    return tf.gather(x, t)[:, None, None, None]\n",
    "\n",
    "def Filter(image,model=\"BLUR\"): #均值模糊\n",
    "    if model == \"conv2D\":\n",
    "        kernel = np.ones((3, 3)) / 9\n",
    "        dst = cv2.filter2D(image, -1, kernel)\n",
    "    if model == \"BLUR\":\n",
    "        dst = cv2.blur(image, (10, 10))\n",
    "    if model == \"Guass\":\n",
    "        dst = cv2.GaussianBlur(image, (0, 0), 2)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################util#########################\n",
    "class Image_data:\n",
    "\n",
    "    def __init__(self, img_size, dataset_path):\n",
    "        self.img_size = img_size\n",
    "        self.dataset_path = dataset_path\n",
    "\n",
    "\n",
    "    def image_processing(self, filename):\n",
    "\n",
    "        x = tf.io.read_file(filename)\n",
    "        x_decode = tf.image.decode_jpeg(x, channels=3, dct_method='INTEGER_ACCURATE')\n",
    "        img = tf.image.resize(x_decode, [self.img_size, self.img_size], antialias=True, method=tf.image.ResizeMethod.BICUBIC)\n",
    "        img = preprocess_fit_train_image(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def preprocess(self):\n",
    "\n",
    "        self.train_images = glob(os.path.join(self.dataset_path, '*.png')) + glob(os.path.join(self.dataset_path, '*.jpg'))\n",
    "\n",
    "def adjust_dynamic_range(images, range_in, range_out, out_dtype):\n",
    "    scale = (range_out[1] - range_out[0]) / (range_in[1] - range_in[0])\n",
    "    bias = range_out[0] - range_in[0] * scale\n",
    "    images = images * scale + bias\n",
    "    images = tf.clip_by_value(images, range_out[0], range_out[1])\n",
    "    images = tf.cast(images, dtype=out_dtype)\n",
    "    return images\n",
    "\n",
    "def random_flip_left_right(images):\n",
    "    s = tf.shape(images)\n",
    "    mask = tf.random.uniform([1, 1, 1], 0.0, 1.0)\n",
    "    mask = tf.tile(mask, [s[0], s[1], s[2]]) # [h, w, c]\n",
    "    images = tf.where(mask < 0.5, images, tf.reverse(images, axis=[1]))\n",
    "    return images\n",
    "\n",
    "def preprocess_fit_train_image(images):\n",
    "    images = adjust_dynamic_range(images, range_in=(0.0, 255.0), range_out=(-1.0, 1.0), out_dtype=tf.dtypes.float32)\n",
    "    images = random_flip_left_right(images)\n",
    "    # images = tf.transpose(images, [2, 0, 1])\n",
    "\n",
    "    return images\n",
    "\n",
    "def preprocess_image(images):\n",
    "    images = adjust_dynamic_range(images, range_in=(0.0, 255.0), range_out=(-1.0, 1.0), out_dtype=tf.dtypes.float32)\n",
    "    # images = tf.transpose(images, [2, 0, 1])\n",
    "\n",
    "    return images\n",
    "\n",
    "def postprocess_images(images):\n",
    "    images = adjust_dynamic_range(images, range_in=(-1.0, 1.0), range_out=(0.0, 255.0), out_dtype=tf.dtypes.float32)\n",
    "    # images = tf.transpose(images, [0, 2, 3, 1])\n",
    "    images = tf.cast(images, dtype=tf.dtypes.uint8)\n",
    "    return images\n",
    "\n",
    "def load_images(image_path, img_width, img_height, img_channel):\n",
    "\n",
    "    # from PIL import Image\n",
    "    if img_channel == 1 :\n",
    "        img = cv2.imread(image_path, flags=cv2.IMREAD_GRAYSCALE)\n",
    "    else :\n",
    "        img = cv2.imread(image_path, flags=cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # img = cv2.resize(img, dsize=(img_width, img_height))\n",
    "    img = tf.image.resize(img, [img_height, img_width], antialias=True, method=tf.image.ResizeMethod.BICUBIC)\n",
    "    img = preprocess_image(img)\n",
    "\n",
    "    if img_channel == 1 :\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "    else :\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    return img\n",
    "\n",
    "def save_images(images, size, image_path):\n",
    "    # size = [height, width]\n",
    "    return imsave(postprocess_images(images), size, image_path)\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    images = merge(images, size)\n",
    "    images = cv2.cvtColor(images.astype('uint8'), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    return cv2.imwrite(path, images)\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[h*j:h*(j+1), w*i:w*(i+1), :] = image\n",
    "\n",
    "    return img\n",
    "\n",
    "def str2bool(x):\n",
    "    return x.lower() in ('true')\n",
    "\n",
    "def check_folder(log_dir):\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    return log_dir\n",
    "\n",
    "def automatic_gpu_usage() :\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "\n",
    "def multi_gpu_loss(x, global_batch_size):\n",
    "    ndim = len(x.shape)\n",
    "    no_batch_axis = list(range(1, ndim))\n",
    "    x = tf.reduce_mean(x, axis=no_batch_axis)\n",
    "    x = tf.reduce_sum(x) / global_batch_size\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################layers############################\n",
    "# building block modules\n",
    "class Block(Layer):\n",
    "    def __init__(self, dim, groups=8):\n",
    "        super(Block, self).__init__()\n",
    "        self.proj = nn.Conv2D(dim, kernel_size=3, strides=1, padding='SAME')\n",
    "        self.norm = tfa.layers.GroupNormalization(groups, epsilon=1e-05)\n",
    "        self.act = SiLU() # x * sigmoid(x)\n",
    "\n",
    "    def call(self, x, scale_shift=None, training=True):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x, training=training)\n",
    "\n",
    "        if exists(scale_shift):\n",
    "            scale, shift = scale_shift\n",
    "            x = x * (scale + 1) + shift\n",
    "\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class ResnetBlock(Layer):\n",
    "    def __init__(self, dim, dim_out, time_emb_dim=None, groups=8):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "\n",
    "        self.mlp = Sequential([\n",
    "            SiLU(),\n",
    "            nn.Dense(units=dim_out * 2)\n",
    "        ]) if exists(time_emb_dim) else None\n",
    "\n",
    "        self.block1 = Block(dim_out, groups=groups)\n",
    "        self.block2 = Block(dim_out, groups=groups)\n",
    "        self.res_conv = nn.Conv2D(filters=dim_out, kernel_size=1, strides=1) if dim != dim_out else Identity()\n",
    "\n",
    "    def call(self, x, time_emb=None, training=True):\n",
    "        scale_shift = None\n",
    "        if exists(self.mlp) and exists(time_emb):\n",
    "            time_emb = self.mlp(time_emb)\n",
    "            time_emb = rearrange(time_emb, 'b c -> b 1 1 c')\n",
    "            scale_shift = tf.split(time_emb, num_or_size_splits=2, axis=-1)\n",
    "\n",
    "        h = self.block1(x, scale_shift=scale_shift, training=training)\n",
    "        h = self.block2(h, training=training)\n",
    "\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "class LinearAttention(Layer):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super(LinearAttention, self).__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        self.hidden_dim = dim_head * heads\n",
    "\n",
    "        self.attend = nn.Softmax()\n",
    "        self.to_qkv = nn.Conv2D(filters=self.hidden_dim * 3, kernel_size=1, strides=1, use_bias=False)\n",
    "\n",
    "        self.to_out = Sequential([\n",
    "            nn.Conv2D(filters=dim, kernel_size=1, strides=1),\n",
    "            LayerNorm(dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        b, h, w, c = x.shape\n",
    "        qkv = self.to_qkv(x)\n",
    "        qkv = tf.split(qkv, num_or_size_splits=3, axis=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b x y (h c) -> b h c (x y)', h=self.heads), qkv)\n",
    "\n",
    "        q = tf.nn.softmax(q, axis=-2)\n",
    "        k = tf.nn.softmax(k, axis=-1)\n",
    "\n",
    "        q = q * self.scale\n",
    "        context = einsum('b h d n, b h e n -> b h d e', k, v)\n",
    "\n",
    "        out = einsum('b h d e, b h d n -> b h e n', context, q)\n",
    "        out = rearrange(out, 'b h c (x y) -> b x y (h c)', h=self.heads, x=h, y=w)\n",
    "        out = self.to_out(out, training=training)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super(Attention, self).__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        self.hidden_dim = dim_head * heads\n",
    "\n",
    "        self.to_qkv = nn.Conv2D(filters=self.hidden_dim * 3, kernel_size=1, strides=1, use_bias=False)\n",
    "        self.to_out = nn.Conv2D(filters=dim, kernel_size=1, strides=1)\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        b, h, w, c = x.shape\n",
    "        qkv = self.to_qkv(x)\n",
    "        qkv = tf.split(qkv, num_or_size_splits=3, axis=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b x y (h c) -> b h c (x y)', h=self.heads), qkv)\n",
    "        q = q * self.scale\n",
    "\n",
    "        sim = einsum('b h d i, b h d j -> b h i j', q, k)\n",
    "        sim_max = tf.stop_gradient(tf.expand_dims(tf.argmax(sim, axis=-1), axis=-1))\n",
    "        sim_max = tf.cast(sim_max, tf.float32)\n",
    "        sim = sim - sim_max\n",
    "        attn = tf.nn.softmax(sim, axis=-1)\n",
    "\n",
    "        out = einsum('b h i j, b h d j -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h (x y) d -> b x y (h d)', x = h, y = w)\n",
    "        out = self.to_out(out, training=training)\n",
    "\n",
    "        return out\n",
    "\n",
    "class MLP(Layer):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = Sequential([\n",
    "            Rearrange('... -> ... 1'), # expand_dims(axis=-1)\n",
    "            nn.Dense(units=hidden_dim),\n",
    "            GELU(),\n",
    "            LayerNorm(hidden_dim),\n",
    "            nn.Dense(units=hidden_dim),\n",
    "            GELU(),\n",
    "            LayerNorm(hidden_dim),\n",
    "            nn.Dense(units=hidden_dim),\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        return self.net(x, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################network#####################################\n",
    "class Unet(Model):\n",
    "    def __init__(self,\n",
    "                 dim=64,\n",
    "                 init_dim=None,\n",
    "                 out_dim=None,\n",
    "                 dim_mults=(1, 2, 4, 8),\n",
    "                 channels=3,\n",
    "                 resnet_block_groups=8,\n",
    "                 learned_variance=False,\n",
    "                 sinusoidal_cond_mlp=True\n",
    "                 ):\n",
    "        super(Unet, self).__init__()\n",
    "\n",
    "        # determine dimensions\n",
    "        self.channels = channels\n",
    "\n",
    "        init_dim = default(init_dim, dim // 3 * 2)\n",
    "        self.init_conv = nn.Conv2D(filters=init_dim, kernel_size=7, strides=1, padding='SAME')\n",
    "\n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        block_klass = partial(ResnetBlock, groups = resnet_block_groups)\n",
    "\n",
    "        # time embeddings\n",
    "        time_dim = dim * 4\n",
    "        self.sinusoidal_cond_mlp = sinusoidal_cond_mlp\n",
    "\n",
    "        if sinusoidal_cond_mlp:\n",
    "            self.time_mlp = Sequential([\n",
    "                SinusoidalPosEmb(dim),\n",
    "                nn.Dense(units=time_dim),\n",
    "                GELU(),\n",
    "                nn.Dense(units=time_dim)\n",
    "            ])\n",
    "        else:\n",
    "            self.time_mlp = MLP(time_dim)\n",
    "\n",
    "        # layers\n",
    "        self.downs = []\n",
    "        self.ups = []\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append([\n",
    "                block_klass(dim_in, dim_out, time_emb_dim=time_dim),\n",
    "                block_klass(dim_out, dim_out, time_emb_dim=time_dim),\n",
    "                Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
    "                Downsample(dim_out) if not is_last else Identity()\n",
    "            ])\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
    "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.ups.append([\n",
    "                block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),\n",
    "                block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n",
    "                Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
    "                Upsample(dim_in) if not is_last else Identity()\n",
    "            ])\n",
    "\n",
    "        default_out_dim = channels * (1 if not learned_variance else 2)\n",
    "        self.out_dim = default(out_dim, default_out_dim)\n",
    "\n",
    "        self.final_conv = Sequential([\n",
    "            block_klass(dim * 2, dim),\n",
    "            nn.Conv2D(filters=self.out_dim, kernel_size=1, strides=1)\n",
    "        ])\n",
    "\n",
    "    def call(self, x, time=None, training=True, **kwargs):\n",
    "        x = self.init_conv(x)\n",
    "        t = self.time_mlp(time)\n",
    "\n",
    "        h = []\n",
    "\n",
    "        for block1, block2, attn, downsample in self.downs:\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "\n",
    "        for block1, block2, attn, upsample in self.ups:\n",
    "            x = tf.concat([x, h.pop()], axis=-1)\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            x = upsample(x)\n",
    "\n",
    "        x = tf.concat([x, h.pop()], axis=-1)\n",
    "        x = self.final_conv(x)\n",
    "        return x\n",
    "\n",
    "class GaussianDiffusion(Model): \n",
    "    def __init__(self, image_size, timesteps=200):\n",
    "        super(GaussianDiffusion, self).__init__()\n",
    "        self.timesteps = timesteps\n",
    "        self.image_size = image_size\n",
    "    def sample_timesteps(self, n, t_cut=None):\n",
    "        if t_cut==None:\n",
    "            sample_t = tf.random.uniform(shape=[n], minval=1, maxval=self.timesteps, dtype=tf.int32)\n",
    "        else:\n",
    "            sample_t = tf.random.uniform(shape=[n], minval=1, maxval=t_cut, dtype=tf.int32)\n",
    "        return sample_t\n",
    "\n",
    "    def noise_images(self, x, t, filtersize): # forward process q ##########正向disfussion过程###############\n",
    "        xt =[]\n",
    "        for batch in range(len(x)):\n",
    "            tem_x = x[batch]\n",
    "            tem_t= np.max(t[batch]) #随便取个值\n",
    "            for i in range(tem_t):\n",
    "                tem_x1 = tem_x\n",
    "                tem_x = cv2.GaussianBlur(tem_x,(filtersize,filtersize),0,0)\n",
    "            xt.append(tem_x) \n",
    "        xt = np.array(xt)\n",
    "        return xt #t时刻噪声图\n",
    "\n",
    "    def sample(self, model, n, start_x=None, start_t=None, end_t=None): # reverse process p ##########反向disfussion过程###############\n",
    "        if start_x is None:\n",
    "            x = tf.random.normal(shape=[n, self.image_size[0], self.image_size[1], 3]) \n",
    "        else:\n",
    "            x = start_x\n",
    "            \n",
    "        if end_t is None:\n",
    "\n",
    "            for i in tqdm(reversed(range(1, self.timesteps if start_t is None else (start_t+1))), desc='sampling loop time step', total=self.timesteps):\n",
    "                t = tf.ones(n, dtype=tf.int32) * i #从最后时刻倒着往前推\n",
    "                x0_predicted =  model(x, t, training=False) ##U-Net输出预测原始图像\n",
    "                x0_predicted = np.array(x0_predicted)\n",
    "                Dt = self.noise_images(x0_predicted,t, filtersize =3)\n",
    "                Dt_1 = self.noise_images(x0_predicted,tf.ones(n, dtype=tf.int32) * (i-1), filtersize =3)\n",
    "                x = x -Dt+ Dt_1\n",
    "                #plt.imshow(x[0]/255.)\n",
    "                #plt.show()\n",
    "        else:\n",
    "            for i in tqdm(reversed(range(end_t, self.timesteps if start_t is None else (start_t+1))), desc='sampling loop time step', total=self.timesteps):\n",
    "                t = tf.ones(n, dtype=tf.int32) * i #从最后时刻倒着往前推\n",
    "                x0_predicted =  model(x, t, training=False) ##U-Net输出预测原始图像\n",
    "                x0_predicted = np.array(x0_predicted)\n",
    "                Dt = self.noise_images(x0_predicted,t, filtersize =3)\n",
    "                Dt_1 = self.noise_images(x0_predicted,tf.ones(n, dtype=tf.int32) * (i-1), filtersize =3)\n",
    "                x = x -Dt+ Dt_1\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b5a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "automatic_gpu_usage()#分配GPU\n",
    "\n",
    "##########加载数据#############\n",
    "image_dir = r'F:\\HCJ_for_AI_training\\NTU\\Nocrack_pavement_train' #(1024,2048,3)\n",
    "\n",
    "def get_image_paths(image_dir:str):\n",
    "    '''\n",
    "    获取所有图片与对应标签的路径 \n",
    "    '''\n",
    "    # 导入数据集\n",
    "    all_file=os.listdir(image_dir)\n",
    "    all_image=[]\n",
    "    for i in range(len(os.listdir(image_dir))):\n",
    "        if os.path.splitext(all_file[i])[1] == \".jpg\":\n",
    "            all_image.append(image_dir + \"\\\\\" +  all_file[i])\n",
    "    all_image=np.array(all_image)[:,np.newaxis]\n",
    "    return all_image\n",
    "\n",
    "paths = get_image_paths(image_dir)\n",
    "#print(paths)\n",
    "#paths_count = len(paths)\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "#创建图片路径及其数字标签的dataset\n",
    "db_train= tf.data.Dataset.from_tensor_slices(paths)\n",
    "db_train = db_train.shuffle(buffer_size=100,seed=2023)\n",
    "db_train = db_train.batch(BATCH_SIZE)\n",
    "\n",
    "def load_image(path,resize=\"None\"):\n",
    "    path = str(path)[12:-26].replace(\"\\\\\\\\\",\"/\")\n",
    "    image = cv2.imread(path)\n",
    "    #resize\n",
    "    image = cv2.resize(image,dsize=(2048,1024),interpolation=cv2.INTER_LINEAR) #小坑：宽度在前，高度在后,得到的size和desize的输入是颠倒的\n",
    "    H = image.shape[0]\n",
    "    W = image.shape[1]\n",
    "    if resize==\"Small\":\n",
    "        image = cv2.resize(image, (W//8,H//8), interpolation=cv2.INTER_AREA)  \n",
    "        \n",
    "    return image\n",
    "\n",
    "def ssim_images(images1,images2,size=3):\n",
    "    Score=[]\n",
    "    for i in range (len(images1)):\n",
    "        grayA = cv2.cvtColor(image1.astype(np.uint8), cv2.COLOR_BGR2GRAY)\n",
    "        grayB = cv2.cvtColor(image2.astype(np.uint8), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # 计算两个灰度图像之间的结构相似度\n",
    "        (score, diff) = structural_similarity(grayA, grayB, win_size=size, full=True)\n",
    "    Score.append(score)\n",
    "    return np.average(Score)\n",
    "\n",
    "\"\"\" Network \"\"\"\n",
    "unet = Unet()\n",
    "diffusion = GaussianDiffusion((128, 256), timesteps=100)\n",
    "\n",
    "\"\"\" Finalize model (build) \"\"\"\n",
    "test_images = np.ones([1, 128, 256, 3])\n",
    "test_t = diffusion.sample_timesteps(n=test_images.shape[0])\n",
    "_ = unet(test_images, test_t)\n",
    "\n",
    "\"\"\" Optimizer \"\"\"\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "unet.load_weights(\"./Diffusion-Unet-blur\")\n",
    "\n",
    "History=[]\n",
    "filtersize=3\n",
    "for epoch in range(0,1000,1):\n",
    "    count=0\n",
    "    db_train = db_train.shuffle(16)\n",
    "    Average_loss=0\n",
    "    for batch_size in db_train:\n",
    "        count+=1\n",
    "        train_image = []\n",
    "        for i in range(len(batch_size)):\n",
    "            train_image.append(load_image(batch_size[i][0],resize=\"Small\"))\n",
    "        train_image=np.array(train_image,dtype=float)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            t = diffusion.sample_timesteps(n=train_image.shape[0]) \n",
    "            x_t = diffusion.noise_images(train_image, t, filtersize) #t时刻噪声图\n",
    "  \n",
    "            predicted_noise_image = unet(x_t, t) #t-1时刻的噪声图\n",
    "    \n",
    "            #loss = tf.square(predicted_noise_image - x_t_1)\n",
    "            #loss = multi_gpu_loss(loss, global_batch_size=BATCH_SIZE)\n",
    "            loss = tf.keras.losses.mean_absolute_error(train_image,predicted_noise_image)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            \n",
    "            gradients = tape.gradient(loss, unet.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, unet.trainable_variables))\n",
    "            #tf.print(\"Loss:%4.2f\" %(loss))   \n",
    "            Average_loss=Average_loss + loss\n",
    "        \n",
    "    Average_loss = Average_loss/count\n",
    "    History.append([epoch, Average_loss])\n",
    "    tf.print(\"=>Epoch%4d  Averageloss:%4.2f\" %(epoch, Average_loss))   \n",
    "\n",
    "    unet.save_weights(\"./Diffusion-Unet-blur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############U-Net####################\n",
    "def Segement(input_size = (128,256,6)):\n",
    "    inputs = tf.keras.Input(shape=input_size)\n",
    "    conv1 = tf.keras.layers.Conv2D(64, 7, activation = 'relu', dilation_rate=2,padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = tf.keras.layers.Conv2D(64, 3, activation = 'relu', dilation_rate=2,padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = tf.keras.layers.Conv2D(128, 3, activation = 'relu', dilation_rate=2,padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = tf.keras.layers.Conv2D(128, 3, activation = 'relu', dilation_rate=2, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = tf.keras.layers. Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = tf.keras.layers.BatchNormalization()(conv4)\n",
    "    conv4 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = tf.keras.layers.BatchNormalization()(conv4)\n",
    "    drop4 = tf.keras.layers.Dropout(0.5)(conv4, training=True)\n",
    "    pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = tf.keras.layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = tf.keras.layers.BatchNormalization()(conv5)\n",
    "    conv5 = tf.keras.layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = tf.keras.layers.BatchNormalization()(conv5)\n",
    "    drop5 = tf.keras.layers.Dropout(0.5)(conv5, training=True)\n",
    "\n",
    "    up6 = tf.keras.layers.Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = tf.keras.layers.concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    \n",
    "\n",
    "    up7 = tf.keras.layers.Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 =tf.keras.layers.concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    \n",
    "\n",
    "    up8 = tf.keras.layers.Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = tf.keras.layers.concatenate([conv2,up8], axis = 3)\n",
    "    conv8 =tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 =tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    \n",
    "\n",
    "    up9 = tf.keras.layers.Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = tf.keras.layers.concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = tf.keras.layers.Conv2D(2, 1, activation = 'softmax', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = conv9)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-label",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###################生成裂缝图像\n",
    "###Step1:随机产生裂缝\n",
    "###Step2:用随机像素替代裂缝位置原本像素制作裂缝图像\n",
    "###裂缝图像diffusion得到去除裂缝的图像\n",
    "###concatenate输入分割网络进行语义分割确定裂缝位置\n",
    "###完成后处理网络\n",
    "\n",
    "image_dir = r'F:\\HCJ_for_AI_training\\NTU\\Standard crack'\n",
    "\n",
    "def get_mask_paths(image_dir:str):\n",
    "    '''\n",
    "    获取所有图片与对应标签的路径 \n",
    "    '''\n",
    "    # 导入数据集\n",
    "    all_file=os.listdir(image_dir)\n",
    "    all_image=[]\n",
    "    for i in range(len(os.listdir(image_dir))):\n",
    "        if os.path.splitext(all_file[i])[1] == \".png\":\n",
    "            all_image.append(image_dir + \"\\\\\" +  all_file[i])\n",
    "    all_image=np.array(all_image)[:,np.newaxis]\n",
    "    return all_image\n",
    "\n",
    "paths = get_mask_paths(image_dir)\n",
    "\n",
    "def load_image_mask(path,resize=\"None\"):\n",
    "    \"\"\"\n",
    "    0, 30, 60, 90, 120 \n",
    "    0为背景\n",
    "    \"\"\"\n",
    "    image = cv2.imread(path[0],0)\n",
    "    image = cv2.resize(image,dsize=(2048,1024),interpolation=cv2.INTER_LINEAR) #小坑：宽度在前，高度在后,得到的size和desize的输入是颠倒的\n",
    "    H = image.shape[0]\n",
    "    W = image.shape[1]\n",
    "    if resize==\"Small\":\n",
    "        image = cv2.resize(image, (W//8,H//8), interpolation=cv2.INTER_AREA)  \n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                if (image[i][j]==90) & (image[i][j]==120) :\n",
    "                    image[i][j]=0\n",
    "                if image[i][j]!=0:\n",
    "                    image[i][j]=1\n",
    "    return image\n",
    "\n",
    "def rotate(image, angle, center=None, scale=1.0):\n",
    "    # grab the dimensions of the image\n",
    "    (h, w) = image.shape[:2]\n",
    "    # if the center is None, initialize it as the center of\n",
    "    # the image\n",
    "    if center is None:\n",
    "        center = (w // 2, h // 2)\n",
    "    # perform the rotation\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    # return the rotated image\n",
    "    return rotated\n",
    "\n",
    "Standard_crack = []\n",
    "for i in range(len(paths)):\n",
    "    mask  = np.array(load_image_mask(paths[i],resize=\"Small\"))\n",
    "    Standard_crack.append(mask)\n",
    "\n",
    "#随机裂缝生成器\n",
    "def random_crack(Crack_source):\n",
    "\n",
    "    new_image=np.zeros(Crack_source[0].shape)\n",
    "    index_list = np.arange(len(Crack_source))\n",
    "    np.random.shuffle(index_list)\n",
    "    index_list =index_list[:3]\n",
    "    tem=[]\n",
    "    Angle=[0, 45, 90, 135, 180]\n",
    "    for i in range(3):\n",
    "        angle=np.random.choice(Angle)\n",
    "        for h in range(new_image.shape[0]//128):\n",
    "            for w in range(new_image.shape[1]//128):\n",
    "                tem.append(rotate(Standard_crack[index_list[i]],angle)[h*128:(h+1)*128,w*128:(w+1)*128])\n",
    "    select_index = np.arange(len(tem))\n",
    "    np.random.shuffle(select_index)\n",
    "    for h in range(new_image.shape[0]//128):\n",
    "        for w in range(new_image.shape[1]//128):    \n",
    "            new_image[h*128:(h+1)*128,w*128:(w+1)*128] =tem[select_index[h+w]]\n",
    "    return new_image\n",
    "\n",
    "####裂缝图像制作器\n",
    "def origional_to_wcrack(images,Crack_source,model):\n",
    "    new_images=[]\n",
    "    crack_image=[]\n",
    "    Inputdata=[]\n",
    "    for i in range(len(images)):\n",
    "        tem_crack = np.array(random_crack(Standard_crack))[:,:,np.newaxis]\n",
    "        crack_image.append(tem_crack)#记录裂缝\n",
    "        input_data = images[i] *(1-tem_crack) #原始图像扣掉裂纹部分\n",
    "        Inputdata.append(input_data)\n",
    "    Inputdata = np.array(Inputdata)\n",
    "    crack_image = np.array(crack_image)\n",
    "    \"\"\"\n",
    "    plt.imshow(crack_image[0]/255)\n",
    "    plt.show()\n",
    "    plt.imshow(Inputdata[0]/255)\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    w_crack_image = model(Inputdata) #融合\n",
    "    \"\"\"\n",
    "    plt.imshow(w_crack_image[0]/255)\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    tem = w_crack_image * crack_image #只保留融合的裂纹\n",
    "    dtem = images * (1-crack_image) #只保留原始图像\n",
    "    new_images = tem+dtem #重新组合\n",
    "    \"\"\"\n",
    "    plt.imshow(new_images[0]/255)\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    return new_images,crack_image\n",
    "\n",
    "image_dir = r'F:\\HCJ_for_AI_training\\NTU\\Nocrack_pavement_train' \n",
    "\n",
    "def get_image_paths(image_dir:str):\n",
    "    '''\n",
    "    获取所有图片与对应标签的路径 \n",
    "    '''\n",
    "    # 导入数据集\n",
    "    all_file=os.listdir(image_dir)\n",
    "    all_image=[]\n",
    "    for i in range(len(os.listdir(image_dir))):\n",
    "        if os.path.splitext(all_file[i])[1] == \".jpg\":\n",
    "            all_image.append(image_dir + \"\\\\\" +  all_file[i])\n",
    "    all_image=np.array(all_image)[:,np.newaxis]\n",
    "    return all_image\n",
    "\n",
    "paths = get_image_paths(image_dir)\n",
    "\n",
    "def load_image_db(path,resize=\"None\"):\n",
    "    path = str(path)[12:-26].replace(\"\\\\\\\\\",\"/\")\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image,dsize=(2048,1024),interpolation=cv2.INTER_LINEAR) #小坑：宽度在前，高度在后,得到的size和desize的输入是颠倒的\n",
    "    H = image.shape[0]\n",
    "    W = image.shape[1]\n",
    "    if resize==\"Small\":\n",
    "        image = cv2.resize(image, (W//8,H//8), interpolation=cv2.INTER_AREA)  \n",
    "    return image\n",
    "\n",
    "#创建图片路径及其数字标签的dataset\n",
    "BATCH_SIZE=2\n",
    "db_train= tf.data.Dataset.from_tensor_slices(paths)\n",
    "db_train = db_train.shuffle(buffer_size=100,seed=2023)\n",
    "db_train = db_train.batch(BATCH_SIZE)\n",
    "\n",
    "#Network \n",
    "unet = Unet()\n",
    "diffusion = GaussianDiffusion((128, 256,3), timesteps=100)\n",
    "\n",
    "#Finalize model (build)\n",
    "test_images = np.ones([1, 128, 256, 3])\n",
    "test_t = diffusion.sample_timesteps(n=test_images.shape[0])\n",
    "_ = unet(test_images, test_t)\n",
    "\n",
    "#Add weights\n",
    "unet.load_weights(\"./Diffusion-Unet-blur\")\n",
    "G_model = Generated_image()\n",
    "G_model.load_weights(\"./colddiffusiongenerated_model\") ##使用预训练网络融合生成合成异常样本效果更好，与论文版本不同\n",
    "S_model = Segement()\n",
    "\n",
    "count=0\n",
    "O_image=[]\n",
    "Wc_image=[]\n",
    "Crack=[]\n",
    "for epoch in range(0,200,1):\n",
    "    count+=1\n",
    "    Average_loss=0\n",
    "    for batch_size in db_train:\n",
    "        train_image = []\n",
    "        for i in range(len(batch_size)):\n",
    "            train_image.append(load_image_db(batch_size[i][0],resize=\"Small\"))\n",
    "        new_image, mask_image  = origional_to_wcrack(train_image,Standard_crack,G_model)\n",
    "        new_image = np.array(new_image,dtype = np.float32)\n",
    "        noise_image = diffusion.noise_images(x=new_image, t=tf.ones(BATCH_SIZE, dtype=tf.int32) * 50, filtersize =3) \n",
    "        Generator_image_o= np.array(diffusion.sample(unet,BATCH_SIZE, noise_image ,50))\n",
    "\n",
    "        inputdata = np.concatenate((new_image,Generator_image_o), axis=-1)\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            predicted_image = S_model(inputdata) \n",
    "\n",
    "            loss = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(mask_image,predicted_image))\n",
    "\n",
    "        gradients = tape.gradient(loss, S_model.trainable_variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(gradients,S_model.trainable_variables))\n",
    "\n",
    "        Average_loss=Average_loss + loss\n",
    "\n",
    "    Average_loss = Average_loss/int(len(index_list)/2)\n",
    "    History.append([epoch, Average_loss])\n",
    "    tf.print(\"=>Epoch%4d  Averageloss:%4.2f\" %(epoch, Average_loss))   \n",
    "\n",
    "    S_model.save_weights(\"./colddiffusion_postprocess_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-architect",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
